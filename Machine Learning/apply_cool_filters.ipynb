{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 's' to capture an image.\n",
      "Image captured.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jatin\\AppData\\Roaming\\Python\\Python311\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize MediaPipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True)\n",
    "\n",
    "# Load filter images (make sure they have transparent backgrounds)\n",
    "sunglasses = cv2.imread('googles.png', cv2.IMREAD_UNCHANGED)  # Sunglasses image with alpha channel (RGBA)\n",
    "star = cv2.imread('star.png', cv2.IMREAD_UNCHANGED)  # Star image with alpha channel (RGBA)\n",
    "\n",
    "def overlay_filter(image, filter_img, position, size):\n",
    "    # Resize filter image\n",
    "    filter_img = cv2.resize(filter_img, size)\n",
    "\n",
    "    # Extract RGBA channels from the filter image\n",
    "    alpha_s = filter_img[:, :, 3] / 255.0\n",
    "    alpha_l = 1.0 - alpha_s\n",
    "\n",
    "    x, y = position\n",
    "\n",
    "    # Overlay the filter on the original image\n",
    "    for c in range(0, 3):\n",
    "        image[y:y + filter_img.shape[0], x:x + filter_img.shape[1], c] = (\n",
    "            alpha_s * filter_img[:, :, c] + alpha_l * image[y:y + filter_img.shape[0], x:x + filter_img.shape[1], c]\n",
    "        )\n",
    "\n",
    "    return image\n",
    "\n",
    "def apply_filters(image, landmarks):\n",
    "    h, w, _ = image.shape\n",
    "\n",
    "    # Landmark points for sunglasses (using eyes region)\n",
    "    left_eye = landmarks[33]\n",
    "    right_eye = landmarks[263]\n",
    "\n",
    "    # Calculate the size and position for sunglasses\n",
    "    googles_width = int(abs(right_eye.x - left_eye.x) * w * 2)  # Adjust size\n",
    "    googles_height = int(googles_width * 0.4)  # Adjust proportion\n",
    "    x = int(left_eye.x * w) - googles_width // 4\n",
    "    y = int(left_eye.y * h) - googles_height // 2\n",
    "\n",
    "    # Overlay sunglasses filter\n",
    "    image = overlay_filter(image, sunglasses, (x, y), (googles_width, googles_height))\n",
    "\n",
    "    # Landmark point for the star filter (above forehead)\n",
    "    forehead = landmarks[10]\n",
    "    star_size = 50  # Size of the star\n",
    "    x = int(forehead.x * w) - star_size // 2\n",
    "    y = int(forehead.y * h) - star_size - 30  # Adjust the position above forehead\n",
    "\n",
    "    # Overlay star filter\n",
    "    image = overlay_filter(image, star, (x, y), (star_size, star_size))\n",
    "\n",
    "    return image\n",
    "\n",
    "def capture_image_and_apply_filters():\n",
    "    # Initialize webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video capture.\")\n",
    "        return\n",
    "\n",
    "    print(\"Press 's' to capture an image.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        cv2.imshow('Webcam', frame)\n",
    "\n",
    "        # Capture image on 's' key press\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('s'):\n",
    "            print(\"Image captured.\")\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Convert the frame to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect facial landmarks\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "    if results.multi_face_landmarks:\n",
    "        landmarks = results.multi_face_landmarks[0].landmark\n",
    "        frame = apply_filters(frame, landmarks)\n",
    "\n",
    "    # Display the final image with filters\n",
    "    cv2.imshow('Filtered Image', frame)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    capture_image_and_apply_filters()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 's' to capture an image.\n",
      "Image captured.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jatin\\AppData\\Roaming\\Python\\Python311\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
