{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset head:\n",
      "    Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRation  \\\n",
      "0  28395    610.291       208.178117       173.888747      1.197191   \n",
      "1  28734    638.018       200.524796       182.734419      1.097356   \n",
      "2  29380    624.110       212.826130       175.931143      1.209713   \n",
      "3  30008    645.884       210.557999       182.516516      1.153638   \n",
      "4  30140    620.134       201.847882       190.279279      1.060798   \n",
      "\n",
      "   Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  roundness  \\\n",
      "0      0.549812       28715     190.141097  0.763923  0.988856   0.958027   \n",
      "1      0.411785       29172     191.272750  0.783968  0.984986   0.887034   \n",
      "2      0.562727       29690     193.410904  0.778113  0.989559   0.947849   \n",
      "3      0.498616       30724     195.467062  0.782681  0.976696   0.903936   \n",
      "4      0.333680       30417     195.896503  0.773098  0.990893   0.984877   \n",
      "\n",
      "   Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  \n",
      "0     0.913358      0.007332      0.003147      0.834222      0.998724  \n",
      "1     0.953861      0.006979      0.003564      0.909851      0.998430  \n",
      "2     0.908774      0.007244      0.003048      0.825871      0.999066  \n",
      "3     0.928329      0.007017      0.003215      0.861794      0.994199  \n",
      "4     0.970516      0.006697      0.003665      0.941900      0.999166  \n",
      "\n",
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13611 entries, 0 to 13610\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Area             13611 non-null  int64  \n",
      " 1   Perimeter        13611 non-null  float64\n",
      " 2   MajorAxisLength  13611 non-null  float64\n",
      " 3   MinorAxisLength  13611 non-null  float64\n",
      " 4   AspectRation     13611 non-null  float64\n",
      " 5   Eccentricity     13611 non-null  float64\n",
      " 6   ConvexArea       13611 non-null  int64  \n",
      " 7   EquivDiameter    13611 non-null  float64\n",
      " 8   Extent           13611 non-null  float64\n",
      " 9   Solidity         13611 non-null  float64\n",
      " 10  roundness        13611 non-null  float64\n",
      " 11  Compactness      13611 non-null  float64\n",
      " 12  ShapeFactor1     13611 non-null  float64\n",
      " 13  ShapeFactor2     13611 non-null  float64\n",
      " 14  ShapeFactor3     13611 non-null  float64\n",
      " 15  ShapeFactor4     13611 non-null  float64\n",
      "dtypes: float64(14), int64(2)\n",
      "memory usage: 1.7 MB\n",
      "None\n",
      "\n",
      "Data processing complete.\n",
      "Training set size: 10888\n",
      "Test set size: 2723\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "def process_data(file_path, target_column):\n",
    "    # Load the dataset\n",
    "    data = pd.read_excel(file_path)\n",
    "    \n",
    "\n",
    "    data = data.drop(columns=['Class'])\n",
    "    # Display basic information about the dataset\n",
    "    print(\"Dataset head:\")\n",
    "    print(data.head())\n",
    "    print(\"\\nDataset info:\")\n",
    "    print(data.info())\n",
    "\n",
    "    # Handling missing values\n",
    "    data = data.fillna(data.mean())  # Filling numeric missing values with mean\n",
    "\n",
    "    # Encoding categorical columns\n",
    "    categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "    label_encoders = {}\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        data[col] = le.fit_transform(data[col])\n",
    "        label_encoders[col] = le\n",
    "    \n",
    "    # Separate features and target variable\n",
    "    X = data.drop(target_column, axis=1)\n",
    "    y = data[target_column]\n",
    "    \n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Split the dataset into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    print(\"\\nData processing complete.\")\n",
    "    print(f\"Training set size: {X_train.shape[0]}\")\n",
    "    print(f\"Test set size: {X_test.shape[0]}\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = 'Dry_Bean_Dataset.xlsx'  # Replace with your dataset file path\n",
    "    target_column = 'Compactness'  # Replace with your target column name\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = process_data(file_path, target_column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
